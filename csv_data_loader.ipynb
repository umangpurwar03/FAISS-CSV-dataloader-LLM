{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV file: data\\Superstore 2023.csv\n",
      "Texts splitted for CSV file: data\\Superstore 2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GEN_AI\\NLP\\langchain\\data_loaders_and_database\\faiss_db\\csv_data_loader\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings created for CSV file: data\\Superstore 2023.csv\n",
      "Vector store created for CSV file: data\\Superstore 2023.csv\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "import threading\n",
    "\n",
    "# Define paths\n",
    "data_dir = 'data'\n",
    "faiss_db = 'vectorstore/db_faiss'\n",
    "\n",
    "def process_csv_file(csv_path):\n",
    "    # Load the CSV file using CSVLoader\n",
    "    loader = CSVLoader(file_path=csv_path, encoding=\"utf-8\", csv_args={'delimiter': ','})\n",
    "    document = loader.load()\n",
    "    print(f\"Loaded CSV file: {csv_path}\")\n",
    "\n",
    "    # Initialize a text splitter to divide documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    texts = text_splitter.split_documents(document)\n",
    "    print(f\"Texts splitted for CSV file: {csv_path}\")\n",
    "\n",
    "    # Initialize HuggingFaceEmbeddings using a specific model\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', model_kwargs={'device': 'cpu'})\n",
    "    print(f\"Embeddings created for CSV file: {csv_path}\")\n",
    "\n",
    "    # Create a vector store using FAISS from the text chunks and embeddings\n",
    "    db = FAISS.from_documents(texts, embeddings)\n",
    "    print(f\"Vector store created for CSV file: {csv_path}\")\n",
    "\n",
    "    # Save the vector store locally\n",
    "    db.save_local(os.path.join(faiss_db, f\"{os.path.basename(csv_path)}_db\"))\n",
    "\n",
    "def process_csv_files_in_parallel():\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(faiss_db):\n",
    "        os.makedirs(faiss_db)\n",
    "\n",
    "    # List all CSV files in the directory\n",
    "    csv_files = [file for file in os.listdir(data_dir) if file.endswith('.csv')]\n",
    "\n",
    "    # Create threads for each CSV file processing\n",
    "    threads = []\n",
    "    for csv_file in csv_files:\n",
    "        csv_path = os.path.join(data_dir, csv_file)\n",
    "        thread = threading.Thread(target=process_csv_file, args=(csv_path,))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    # Wait for all threads to complete\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_csv_files_in_parallel()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
